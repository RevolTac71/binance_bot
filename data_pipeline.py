import asyncio
import functools
import ccxt.async_support as ccxt
import pandas as pd
import numpy as np
import pandas_ta as ta
import pandas_ta as ta
from ccxt.base.errors import RateLimitExceeded, RequestTimeout, NetworkError
from config import settings, logger


# -- Exponential Backoff Decorator --
def with_exponential_backoff(max_retries=5, base_delay=1.0, max_delay=60.0):
    """
    API 429 ì—ëŸ¬(RateLimitExceeded)ë‚˜ íƒ€ì„ì•„ì›ƒ ë°œìƒ ì‹œ,
    ëŒ€ê¸° ì‹œê°„ì„ ì ì§„ì ìœ¼ë¡œ(ì§€ìˆ˜ì ) ì¦ê°€ì‹œì¼œê°€ë©° ì¬ì‹œë„í•˜ëŠ” ë°ì½”ë ˆì´í„°ì…ë‹ˆë‹¤.
    """

    def decorator(func):
        @functools.wraps(func)
        async def wrapper(*args, **kwargs):
            retries = 0
            delay = base_delay
            while True:
                try:
                    return await func(*args, **kwargs)
                except (RateLimitExceeded, RequestTimeout, NetworkError) as e:
                    retries += 1
                    if retries > max_retries:
                        logger.error(
                            f"ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜({max_retries}) ì´ˆê³¼. {func.__name__} ìµœì¢… ì—ëŸ¬: {e}"
                        )
                        raise e

                    logger.warning(
                        f"API ì—ëŸ¬ ë°œìƒ ({e.__class__.__name__}): {e}. {delay}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„ ({retries}/{max_retries})..."
                    )
                    await asyncio.sleep(delay)
                    delay = min(max_delay, delay * 2)  # ì§€ìˆ˜ ì¦ê°€, ìµœëŒ“ê°’ max_delay

        return wrapper

    return decorator


class DataPipeline:
    def __init__(self):
        # ë°”ì´ë‚¸ìŠ¤ ì„ ë¬¼(USDâ“ˆ-M Futures) ì‹œì¥ í™˜ê²½ ì„¤ì • (V11)
        api_key = (
            settings.BINANCE_TESTNET_API_KEY
            if settings.USE_TESTNET
            else settings.BINANCE_API_KEY
        )
        api_secret = (
            settings.BINANCE_TESTNET_API_SECRET
            if settings.USE_TESTNET
            else settings.BINANCE_API_SECRET
        )

        self.exchange = ccxt.binance(
            {
                "apiKey": api_key,
                "secret": api_secret,
                "enableRateLimit": True,  # ccxt ë‚´ì¥ ì†ë„ ì œí•œê¸° í™œì„±í™”
                "options": {
                    "defaultType": "future",
                    "warnOnFetchOpenOrdersWithoutSymbol": False,  # ì´ˆê¸° ë™ê¸°í™” ì‹œ ì „ì²´ ëŒ€ê¸°ì£¼ë¬¸ ì¡°íšŒ ê²½ê³  ë¬´ì‹œ
                },  # í˜„ë¬¼(spot) -> ì„ ë¬¼(future) ë³€ê²½
            }
        )

        # Testnet (Sandbox) ëª¨ë“œ í™œì„±í™” ì²˜ë¦¬
        if settings.USE_TESTNET:
            self.exchange.set_sandbox_mode(True)
            logger.info(
                "ğŸ§ª [TESTNET MODE] ë°”ì´ë‚¸ìŠ¤ ì„ ë¬¼ í…ŒìŠ¤íŠ¸ë„· í™˜ê²½ìœ¼ë¡œ CCXT ê°ì²´ ì—°ê²°ì´ ì„¸íŒ…ë˜ì—ˆìŠµë‹ˆë‹¤."
            )

    async def close(self):
        """ê±°ë˜ì†Œ ì„¸ì…˜ì„ ì•ˆì „í•˜ê²Œ ì¢…ë£Œí•©ë‹ˆë‹¤."""
        await self.exchange.close()

    @with_exponential_backoff(max_retries=5)
    async def fetch_ohlcv_since(
        self, symbol: str, timeframe: str = "1m", since: int = None
    ) -> pd.DataFrame:
        """
        ì£¼ì–´ì§„ ì‹¬ë³¼ì˜ ë°”ì´ë‚¸ìŠ¤ ìº”ë“¤ ë°ì´í„°ë¥¼ ë¹„ë™ê¸°ë¡œ ë¶ˆëŸ¬ì™€ DataFrameìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        (V15: 1ë¶„ë´‰ ë‹¹ì¼ ëˆ„ì  ë°ì´í„° ìˆ˜ì§‘ì„ ìœ„í•´ ìµœëŒ€ í•œë„ 1500ê°œë¥¼ ëŒì–´ì˜µë‹ˆë‹¤)
        """
        candles = await self.exchange.fetch_ohlcv(
            symbol, timeframe, since=since, limit=1500
        )

        df = pd.DataFrame(
            candles, columns=["timestamp", "open", "high", "low", "close", "volume"]
        )
        df["datetime"] = pd.to_datetime(df["timestamp"], unit="ms")
        df.set_index("datetime", inplace=True)
        return df

    def calculate_vwap_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        [V15.0] ì¼ìë³„(Daily) 00:00 UTC(09:00 KST) ê¸°ì¤€ ëˆ„ì  ê·¸ë£¹í™”ëœ Anchored VWAP ë° ì œë°˜ ì§€í‘œ ì—°ì‚°
        (ìˆ˜ì§‘ëœ ì „ì²´ 1ë¶„ë´‰ ë°ì´í„° í”„ë ˆì„ì„ ëŒ€ìƒìœ¼ë¡œ í•œë²ˆì— ê³„ì‚°í•©ë‹ˆë‹¤)
        """
        if len(df) == 0:
            return df

        df["hlc3"] = (df["high"] + df["low"] + df["close"]) / 3
        df["vol_hlc3"] = df["hlc3"] * df["volume"]
        df["vol_hlc3_sq"] = df["hlc3"] ** 2 * df["volume"]

        # KST íƒ€ì„ì¡´ ì ìš©ëœ index ê¸°ì¤€ìœ¼ë¡œ dateë¥¼ ì¶”ì¶œí•˜ì—¬ ì¼ìë³„ ëˆ„ì í•© ê³„ì‚° (09:00 ê¸°ì¤€ ë¦¬ì…‹ íš¨ê³¼)
        # ì›¹ì†Œì¼“ í™˜ê²½ ë“±ì—ì„œ ì—¬ëŸ¬ ë‚ ì§œì˜ ë°ì´í„°ê°€ ì„ì—¬ ìˆì–´ë„ ì¼ìë³„ë¡œ VWAPì´ ì •ìƒ ì´ˆê¸°í™”ë©ë‹ˆë‹¤.
        grouped = df.groupby(df.index.date)
        df["cum_vol"] = grouped["volume"].cumsum()
        df["cum_vol_hlc3"] = grouped["vol_hlc3"].cumsum()
        df["cum_vol_hlc3_sq"] = grouped["vol_hlc3_sq"].cumsum()

        # VWAP ê³„ì‚°
        df["VWAP"] = df["cum_vol_hlc3"] / df["cum_vol"]

        # ë¶„ì‚°(Variance) ê³„ì‚° = (ëˆ„ì (ê°€ê²©^2 * ê±°ë˜ëŸ‰) / ëˆ„ì ê±°ë˜ëŸ‰) - VWAP^2
        variance = (df["cum_vol_hlc3_sq"] / df["cum_vol"]) - (df["VWAP"] ** 2)
        variance = np.maximum(0, variance)  # ìŒìˆ˜ ë°©ì§€

        # V15.0 í‘œì¤€í¸ì°¨ ë°´ë“œ ë©€í‹°í”Œë¼ì´ì–´ (K = 2.5)
        vwap_mult = (
            float(settings.K_VALUE) if getattr(settings, "K_VALUE", 2.5) else 2.5
        )
        df["StdDev"] = np.sqrt(variance)
        df["Upper_Band"] = df["VWAP"] + df["StdDev"] * vwap_mult
        df["Lower_Band"] = df["VWAP"] - df["StdDev"] * vwap_mult

        # ê³¼ë§¤ë„/ê³¼ë§¤ìˆ˜ íŒë‹¨ì„ ìœ„í•œ RSI (14)
        df.ta.rsi(length=14, append=True, col_names=("RSI_14",))
        # V15.0 ê±°ë˜ëŸ‰ ìŠ¤íŒŒì´í¬ íŒë³„ì„ ìœ„í•œ Volume SMA (20)
        df.ta.sma(close=df["volume"], length=20, append=True, col_names=("Vol_SMA_20",))
        # ë³€ë™ì„± í•„í„° ë° ë™ì  ìµì†ì ˆ ê±°ë¦¬ë¥¼ ìœ„í•œ ë‹¨ê¸° ATR (14)
        df.ta.atr(length=14, append=True, col_names=("ATR_14",))

        # [V15.2] ë™ì  ë³€ë™ì„± í•„í„°ë¥¼ ìœ„í•œ ì¥ê¸° ATR ê³„ì‚° (ê¸°ë³¸ 200)
        atr_long_len = getattr(settings, "ATR_LONG_LEN", 200)
        # ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ê³„ì‚°
        if len(df) > atr_long_len:
            df.ta.atr(
                length=atr_long_len, append=True, col_names=(f"ATR_{atr_long_len}",)
            )
        else:
            df[f"ATR_{atr_long_len}"] = df["ATR_14"]

        return df

    # Top 5 ì•ŒíŠ¸ì½”ì¸ ë™ì  ì¶”ì¶œ
    @with_exponential_backoff(max_retries=3)
    async def fetch_top_altcoins_by_volume(
        self,
        limit: int = 5,
        exclude_symbols: list = [
            "BTC/USDT:USDT",
            "ETH/USDT:USDT",
            "USDC/USDT:USDT",
            "FDUSD/USDT:USDT",
            "TUSD/USDT:USDT",
            "EUR/USDT:USDT",
            "USDP/USDT:USDT",
        ],
    ) -> list:
        """
        ë°”ì´ë‚¸ìŠ¤ ì„ ë¬¼ ì‹œì¥ì—ì„œ 24ì‹œê°„ ê±°ë˜ê¸ˆì•¡(Quote Volume) ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ ì•ŒíŠ¸ì½”ì¸ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
        ìŠ¤í…Œì´ë¸”ì½”ì¸ì´ë‚˜ ë¬´ê±°ìš´ ë¹„íŠ¸, ì´ë”ë¦¬ì›€ì€ ì œì™¸í•©ë‹ˆë‹¤.
        """
        tickers = await self.exchange.fetch_tickers()

        # USDT ê¸°ë°˜ ì„ í˜• ì„ ë¬¼ í‹°ì»¤ í•„í„°ë§ (ì„ ë¬¼ì€ "ADA/USDT:USDT" í˜•íƒœ)
        usdt_pairs = {
            k: v
            for k, v in tickers.items()
            if k.endswith("/USDT:USDT") and k not in exclude_symbols
        }

        # 24ì‹œê°„ ê±°ë˜ëŒ€ê¸ˆ (quoteVolume) ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        sorted_pairs = sorted(
            usdt_pairs.items(), key=lambda x: x[1].get("quoteVolume", 0), reverse=True
        )

        # ì‹¬ë³¼ ì¶”ì¶œ
        top_symbols = [pair[0] for pair in sorted_pairs[:limit]]
        return top_symbols
